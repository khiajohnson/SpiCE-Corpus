{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The SpiCE Corpus SpiCE is an open-access corpus of conversational bilingual Speech in Cantonese and English. SpiCE includes high-quality audio recordings of 30-minute interviews with 34 early bilinguals in each language with accompanying transcriptions and language background informaiton. The corpus was first released in May 2021. Detailed information about the corpus is provided on the design and transcription pages, as well as in Khia's dissertation . Contributors Khia A. Johnson Molly Babel Ivan Fong Nancy Yiu ...and many other members of the Speech-in-Context Lab Citing the corpus When referring to the corpus in the body of your text or presentation, you can call it the \"SpiCE Corpus\" (please keep the letters in their specified cases), but should spell out \"Speech in Cantonese and English\" at least once! You can cite the corpus directly (preferred): @data{johnson_spice_2021, author = {Johnson, Khia A.}, publisher = {Scholars Portal Dataverse}, title = {{SpiCE: Speech in Cantonese and English}}, UNF = {UNF:6:c6HNIwwpBuQOA349cyCu7w==}, year = {2021}, version = {V1}, doi = {10.5683/SP2/MJOXP3}, url = {https://doi.org/10.5683/SP2/MJOXP3} } Alternatively, cite the paper that introduces the corpus: @inproceedings{johnson_lrec_2020, title = {SpiCE: A new open-access corpus of conversational bilingual speech in Cantonese and English}, author = {Johnson, Khia A. and Babel, Molly and Fong, Ivan and Yiu, Nancy}, booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference}, month = may, year = {2020}, address = {Marseille, France}, publisher = {European Language Resources Association}, url = {https://www.aclweb.org/anthology/2020.lrec-1.503}, pages = {4089--4095}, language = {English}, ISBN = {979-10-95546-34-4}, }","title":"Home"},{"location":"#the-spice-corpus","text":"SpiCE is an open-access corpus of conversational bilingual Speech in Cantonese and English. SpiCE includes high-quality audio recordings of 30-minute interviews with 34 early bilinguals in each language with accompanying transcriptions and language background informaiton. The corpus was first released in May 2021. Detailed information about the corpus is provided on the design and transcription pages, as well as in Khia's dissertation .","title":"The SpiCE Corpus"},{"location":"#contributors","text":"Khia A. Johnson Molly Babel Ivan Fong Nancy Yiu ...and many other members of the Speech-in-Context Lab","title":"Contributors"},{"location":"#citing-the-corpus","text":"When referring to the corpus in the body of your text or presentation, you can call it the \"SpiCE Corpus\" (please keep the letters in their specified cases), but should spell out \"Speech in Cantonese and English\" at least once! You can cite the corpus directly (preferred): @data{johnson_spice_2021, author = {Johnson, Khia A.}, publisher = {Scholars Portal Dataverse}, title = {{SpiCE: Speech in Cantonese and English}}, UNF = {UNF:6:c6HNIwwpBuQOA349cyCu7w==}, year = {2021}, version = {V1}, doi = {10.5683/SP2/MJOXP3}, url = {https://doi.org/10.5683/SP2/MJOXP3} } Alternatively, cite the paper that introduces the corpus: @inproceedings{johnson_lrec_2020, title = {SpiCE: A new open-access corpus of conversational bilingual speech in Cantonese and English}, author = {Johnson, Khia A. and Babel, Molly and Fong, Ivan and Yiu, Nancy}, booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference}, month = may, year = {2020}, address = {Marseille, France}, publisher = {European Language Resources Association}, url = {https://www.aclweb.org/anthology/2020.lrec-1.503}, pages = {4089--4095}, language = {English}, ISBN = {979-10-95546-34-4}, }","title":"Citing the corpus"},{"location":"design/","text":"Design overview This section covers general information about SpiCE, including how the corpus was collected, and how the transcriptions were developed. Much of this is also covered in the open-access paper describing the corpus . A phonological corpus What's that? A phonological corpus for spoken language has audio recordings, linguistic annotations at the level of the word and phone, as well as metadata. A phonological corpus should also be representative of the selected population, big enough, and collected for a purpose. A good source of more general information on the topic is The Oxford Handbook of Corpus Phonology . SpiCE is a phonological corpus, albeit one with force-aligned phones . A future release might include hand-corrected phones, but that's a big \u2753 at the moment. If you're interested in contributing to the corpus\u2014hand-correction or anything else\u2014please get in touch! The speech community The Cantonese-speaking community in Metro Vancouver is a unique bilingual community. Not only is Cantonese very widely spoken in the area, it has been for a long time , and by a heterogeneous group of people. Statistics Canada has some useful visualizations for getting a broad picture of the linguistic landscape\u2014in particular: Proportion of mother tongue responses for various regions in Canada from the 2016 Census . Needless to say, there is a lot more that could be said here! Participant recruitment Thirty-four early Cantonese-English bilinguals were recruited from the UBC community in Metro Vancouver, BC, Canada, using language like: Do you speak Cantonese and English? You can be part of a bilingual speech database. We\u2019re studying what makes bilingual speech unique\u2014specifically, how languages influence one another. We are looking for fluent speakers of Cantonese and English, between the ages of 19 and 35 (inclusive), with normal speech and hearing. The study involves two conversational interviews on everyday topics like culture, hobbies, school, community issues, or work. What\u2019s the catch? One interview will be conducted in Cantonese, and the other in English. Both interviews will be recorded and included in an Open Access database, so researchers and developers around the world can play with and learn from your speech. Participation lasts approximately 1.5 hours at UBC (6368 Stores Road, Vancouver, BC). You will be compensated $15 (or receive partial course credit instead, upon request). Participants were recruited from October 2018 through March 2020 via word of mouth, social media, clubs, the UBC linguistics subject pool, and other similar methods. A detailed summary of the participants' language background information is provided in the corpus download . The group of participants recruited for SpiCE reflects the heterogeneity in the speech community.","title":"Design overview"},{"location":"design/#design-overview","text":"This section covers general information about SpiCE, including how the corpus was collected, and how the transcriptions were developed. Much of this is also covered in the open-access paper describing the corpus .","title":"Design overview"},{"location":"design/#a-phonological-corpus","text":"What's that? A phonological corpus for spoken language has audio recordings, linguistic annotations at the level of the word and phone, as well as metadata. A phonological corpus should also be representative of the selected population, big enough, and collected for a purpose. A good source of more general information on the topic is The Oxford Handbook of Corpus Phonology . SpiCE is a phonological corpus, albeit one with force-aligned phones . A future release might include hand-corrected phones, but that's a big \u2753 at the moment. If you're interested in contributing to the corpus\u2014hand-correction or anything else\u2014please get in touch!","title":"A phonological corpus"},{"location":"design/#the-speech-community","text":"The Cantonese-speaking community in Metro Vancouver is a unique bilingual community. Not only is Cantonese very widely spoken in the area, it has been for a long time , and by a heterogeneous group of people. Statistics Canada has some useful visualizations for getting a broad picture of the linguistic landscape\u2014in particular: Proportion of mother tongue responses for various regions in Canada from the 2016 Census . Needless to say, there is a lot more that could be said here!","title":"The speech community"},{"location":"design/#participant-recruitment","text":"Thirty-four early Cantonese-English bilinguals were recruited from the UBC community in Metro Vancouver, BC, Canada, using language like: Do you speak Cantonese and English? You can be part of a bilingual speech database. We\u2019re studying what makes bilingual speech unique\u2014specifically, how languages influence one another. We are looking for fluent speakers of Cantonese and English, between the ages of 19 and 35 (inclusive), with normal speech and hearing. The study involves two conversational interviews on everyday topics like culture, hobbies, school, community issues, or work. What\u2019s the catch? One interview will be conducted in Cantonese, and the other in English. Both interviews will be recorded and included in an Open Access database, so researchers and developers around the world can play with and learn from your speech. Participation lasts approximately 1.5 hours at UBC (6368 Stores Road, Vancouver, BC). You will be compensated $15 (or receive partial course credit instead, upon request). Participants were recruited from October 2018 through March 2020 via word of mouth, social media, clubs, the UBC linguistics subject pool, and other similar methods. A detailed summary of the participants' language background information is provided in the corpus download . The group of participants recruited for SpiCE reflects the heterogeneity in the speech community.","title":"Participant recruitment"},{"location":"download/","text":"Get the SpiCE corpus Download SpiCE is available through the UBC Research Data Collection via Scholars Portal Dataverse. You can access SpiCE from the button below. SpiCE is freely available under a Creative Commons Attribution 4.0 International License . That means you can use, copy, share, and adapt it, as long as you don't release your adaptation with additional restrictions, and you cite the corpus. Download SpiCE Citation As stated on the home page , we prefer that you cite the corpus directly: @data{johnson_spice_2021, author = {Johnson, Khia A.}, publisher = {Scholars Portal Dataverse}, title = {{SpiCE: Speech in Cantonese and English}}, UNF = {UNF:6:c6HNIwwpBuQOA349cyCu7w==}, year = {2021}, version = {V1}, doi = {10.5683/SP2/MJOXP3}, url = {https://doi.org/10.5683/SP2/MJOXP3} } But if you can't do that, then you can also cite the following paper: @inproceedings{johnson_lrec_2020, title = {SpiCE: A new open-access corpus of conversational bilingual speech in Cantonese and English}, author = {Johnson, Khia A. and Babel, Molly and Fong, Ivan and Yiu, Nancy}, booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference}, month = may, year = {2020}, address = {Marseille, France}, publisher = {European Language Resources Association}, url = {https://www.aclweb.org/anthology/2020.lrec-1.503}, pages = {4089--4095}, language = {English}, ISBN = {979-10-95546-34-4}, } What's in the download? The download comes with: A `README.md file (this will give the full rundown) Tabular language background information PDF copy of the language background questionnaire Files used in and produced by the forced alignment process A copy of this documentation (as it was on the release date) 2 languages x 34 talkers = 68 .wav files (stereo, 16-bit, 44.1 kHz) 2 languages x 34 talkers = 68 .TextGrid files (each with 4 tiers: task, utterance, word, phone) The .wav and .TextGrid files have a consitent format. For example, VF21A_Cantonese2_20200131 would correspond to the following: Text What it means Other categories VF Female VF = Male 21 Age varies 19 - 34 Cantonese Language English 2 Interview order 1 20200231 Date in YYYYMMDD varies Unique participant IDs are made up of the first five characters. In this example, that would be VF21A . This ID is used in the language background summary. Ethics The corpus was developed in accordance with the University of British Columbia Behavioural Research Ethics Board (H18-02017). Funding SpiCE was funded by University of British Columbia Public Scholars Initiative and Arts Graduate Research Awards to Khia A. Johnson, and by a Social Sciences and Humanities Research Council of Canada (SSHRC) Insight Grant to Molly Babel.","title":"Download"},{"location":"download/#get-the-spice-corpus","text":"","title":"Get the SpiCE corpus"},{"location":"download/#download","text":"SpiCE is available through the UBC Research Data Collection via Scholars Portal Dataverse. You can access SpiCE from the button below. SpiCE is freely available under a Creative Commons Attribution 4.0 International License . That means you can use, copy, share, and adapt it, as long as you don't release your adaptation with additional restrictions, and you cite the corpus. Download SpiCE","title":"Download"},{"location":"download/#citation","text":"As stated on the home page , we prefer that you cite the corpus directly: @data{johnson_spice_2021, author = {Johnson, Khia A.}, publisher = {Scholars Portal Dataverse}, title = {{SpiCE: Speech in Cantonese and English}}, UNF = {UNF:6:c6HNIwwpBuQOA349cyCu7w==}, year = {2021}, version = {V1}, doi = {10.5683/SP2/MJOXP3}, url = {https://doi.org/10.5683/SP2/MJOXP3} } But if you can't do that, then you can also cite the following paper: @inproceedings{johnson_lrec_2020, title = {SpiCE: A new open-access corpus of conversational bilingual speech in Cantonese and English}, author = {Johnson, Khia A. and Babel, Molly and Fong, Ivan and Yiu, Nancy}, booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference}, month = may, year = {2020}, address = {Marseille, France}, publisher = {European Language Resources Association}, url = {https://www.aclweb.org/anthology/2020.lrec-1.503}, pages = {4089--4095}, language = {English}, ISBN = {979-10-95546-34-4}, }","title":"Citation"},{"location":"download/#whats-in-the-download","text":"The download comes with: A `README.md file (this will give the full rundown) Tabular language background information PDF copy of the language background questionnaire Files used in and produced by the forced alignment process A copy of this documentation (as it was on the release date) 2 languages x 34 talkers = 68 .wav files (stereo, 16-bit, 44.1 kHz) 2 languages x 34 talkers = 68 .TextGrid files (each with 4 tiers: task, utterance, word, phone) The .wav and .TextGrid files have a consitent format. For example, VF21A_Cantonese2_20200131 would correspond to the following: Text What it means Other categories VF Female VF = Male 21 Age varies 19 - 34 Cantonese Language English 2 Interview order 1 20200231 Date in YYYYMMDD varies Unique participant IDs are made up of the first five characters. In this example, that would be VF21A . This ID is used in the language background summary.","title":"What's in the download?"},{"location":"download/#ethics","text":"The corpus was developed in accordance with the University of British Columbia Behavioural Research Ethics Board (H18-02017).","title":"Ethics"},{"location":"download/#funding","text":"SpiCE was funded by University of British Columbia Public Scholars Initiative and Arts Graduate Research Awards to Khia A. Johnson, and by a Social Sciences and Humanities Research Council of Canada (SSHRC) Insight Grant to Molly Babel.","title":"Funding"},{"location":"procedures/","text":"Recording session procedures This page is an extension of the description published in Johnson, Babel, Fong, & Yiu (2020) , and some of the text from the paper is reproduced verbatim. Overview Before coming to the session, all participants completed the UBC Linguistics department language background Qualtrics survey through their UBC Linguistics SONA account\u2014a summary derived from participant responses is included in the corpus download , as is a copy of the survey questions. During the recording session, participants spent approximately 90 minutes in the lab, and completed three tasks for each language (see below). Written informed consent was provided at the beginning of the session. The tasks were ordered from most structured to least structured. The order of languages was counterbalanced\u2014half completed the Cantonese interview first, and the other half completed the English interview first (this information is included in the participant summary file and file names, see below). Participants were given a break between interviews if they wanted one. Recording setup All of the recordings in the SpiCE corpus were created by two Cantonese-English bilingual research assistants, in a quiet room in Stores Road Annex at the University of British Columbia. The participant and research assistants were all seated around a table during the session\u2014Nancy Yiu conducted the interviews, and Ivan Fong managed the recording process. Tools & equipment Audacity 2.2 (and above) A PC laptop Sound Devices USBPre2 Portable Audio Interface AKG C520 head-mounted microphones (worn by Nancy and participant) AKG headphones (worn by Ivan) Settings Stereo (L: participant, R: interviewer), Note: one file was accidentally recorded in mono with just the participant 44.1 KHz sampling rate (or higher, resampled for consistency) 16-bit resolution (or higher, resampled for consistency) Task 1: Sentences Participants read a fixed set of sentences in each language, in the same order. Some sentences contain errors, and were not necessarily repeated. The Cantonese sentences were Chinese New Year themed sentences that were expected to be familiar to participants. Participants were presented with Cantonese characters, Jyutping , and the English translation simultaneously. This was done, as not all participants were expected to be able to read in Cantonese. Characters Jyutping English translations 1. \u65b0\u5e74\u5feb\u6a02 san1 lin4 faai3 lok6 Happy New Year 2. \u606d\u559c\u767c\u8ca1 gung1 hei2 faat3 choi4 Congratulations on happiness and prosperity 3. \u8eab\u9ad4\u5065\u5eb7 san1 tai2 gin6 hong1 May your health be well 4. \u5feb\u9ad8\u9577\u5927 faai3 gou1 zoeng2 dai6 Grow quickly 5. \u9f8d\u99ac\u7cbe\u795e lung4 ma5 zing1 san4 Have the spirit of the horse and dragon 6. \u5b78\u696d\u9032\u6b65 hok6 yip6 zeon3 bou6 Progress in your education 7. \u5e74\u5e74\u6709\u9918 lin4 lin4 yau5 yue4 Excess in each year 8. \u51fa\u5165\u5e73\u5b89 cut1 yap6 ping4 on1 Leave and enter in safety 9. \u5fc3\u60f3\u4e8b\u6210 sam1 soeng2 si6 sing4 Accomplish that which is in your heart 10. \u751f\u610f\u8208\u9686 saang1 yi3 hing1 lung4 Have a prosperous business 11. \u842c\u4e8b\u5982\u610f maan6 si6 yu4 yi3 A thousand things according to your will 12. \u5929\u5929\u5411\u4e0a tin1 tin1 hoeng3 soeng6 Upwards and onwards every day 13. \u7b11\u53e3\u5e38\u958b siu3 hau2 soeng4 hoi1 Laugh with an open mouth frequently 14. \u5927\u5409\u5927\u5229 daai6 gat1 daai6 lei6 Much luck and much prosperity 15. \u4e94\u798f\u81e8\u9580 mm5 fuk1 lam4 mun4 Five blessings for your household 16. \u62db\u8ca1\u9032\u5bf6 ziu1 coi4 zeon3 bou2 Seek wealth welcome in the precious 17. \u76e4\u6eff\u7835\u6eff pun4 mun5 but3 mun5 Basins full of wealth The English sentences include List 60 from the Harvard Sentences and some holiday-themed additions to better match the Cantonese sentences. Thirteen of the sentences are imperatives. English sentence 1. Stop whistling and watch the boys march. 2. Jerk the cord, and out tumbles the gold. 3. Slide the tray across the glass top. 4. The cloud moved in a stately way and was gone. 5. Light maple makes for a swell room. 6. Set the piece here and say nothing. 7. Dull stories make her laugh. 8. A stiff cord will do to fasten your shoe. 9. Get the trust fund to the bank early. 10. Choose between the high road and the low. 11. Wish on every candle for your birthday. 12. Deck the halls with boughs of holly. 13. Ring in the new year with a kiss. 14. Have a spooky Halloween. 15. Enjoy the vacation with your loved ones. 16. Be filled with joy and peace during this time. 17. Relax on your holiday break. Task 2: Storyboard Participants narrated the same cartoon in both languages, usually in just a few minutes. The cartoon\u2014 Thank You Notes \u2014was originally developed by Patrick Littell for linguistics field research and elicited vocabulary related to family members and simple gift-giving. While participants only viewed one panel at a time, here's what the cartoon looked like as a whole: Task 3: Interview The conversational interview accounted for the bulk of the session, and typically lasted around 25 minutes each. The interviews covered a variety of everyday topics such as culture, food, school, hobbies, and family. The sequence of topics with potential follow-up prompts and questions is available in the following documents. Note that the interviews were dynamic, in that the interviewer went along with what the participant wanted to discuss! As such, the content of interviews varies substantially. English interview questions PDF Cantonese interview questions PDF","title":"Recording session procedures"},{"location":"procedures/#recording-session-procedures","text":"This page is an extension of the description published in Johnson, Babel, Fong, & Yiu (2020) , and some of the text from the paper is reproduced verbatim.","title":"Recording session procedures"},{"location":"procedures/#overview","text":"Before coming to the session, all participants completed the UBC Linguistics department language background Qualtrics survey through their UBC Linguistics SONA account\u2014a summary derived from participant responses is included in the corpus download , as is a copy of the survey questions. During the recording session, participants spent approximately 90 minutes in the lab, and completed three tasks for each language (see below). Written informed consent was provided at the beginning of the session. The tasks were ordered from most structured to least structured. The order of languages was counterbalanced\u2014half completed the Cantonese interview first, and the other half completed the English interview first (this information is included in the participant summary file and file names, see below). Participants were given a break between interviews if they wanted one.","title":"Overview"},{"location":"procedures/#recording-setup","text":"All of the recordings in the SpiCE corpus were created by two Cantonese-English bilingual research assistants, in a quiet room in Stores Road Annex at the University of British Columbia. The participant and research assistants were all seated around a table during the session\u2014Nancy Yiu conducted the interviews, and Ivan Fong managed the recording process.","title":"Recording setup"},{"location":"procedures/#tools-equipment","text":"Audacity 2.2 (and above) A PC laptop Sound Devices USBPre2 Portable Audio Interface AKG C520 head-mounted microphones (worn by Nancy and participant) AKG headphones (worn by Ivan)","title":"Tools &amp; equipment"},{"location":"procedures/#settings","text":"Stereo (L: participant, R: interviewer), Note: one file was accidentally recorded in mono with just the participant 44.1 KHz sampling rate (or higher, resampled for consistency) 16-bit resolution (or higher, resampled for consistency)","title":"Settings"},{"location":"procedures/#task-1-sentences","text":"Participants read a fixed set of sentences in each language, in the same order. Some sentences contain errors, and were not necessarily repeated. The Cantonese sentences were Chinese New Year themed sentences that were expected to be familiar to participants. Participants were presented with Cantonese characters, Jyutping , and the English translation simultaneously. This was done, as not all participants were expected to be able to read in Cantonese. Characters Jyutping English translations 1. \u65b0\u5e74\u5feb\u6a02 san1 lin4 faai3 lok6 Happy New Year 2. \u606d\u559c\u767c\u8ca1 gung1 hei2 faat3 choi4 Congratulations on happiness and prosperity 3. \u8eab\u9ad4\u5065\u5eb7 san1 tai2 gin6 hong1 May your health be well 4. \u5feb\u9ad8\u9577\u5927 faai3 gou1 zoeng2 dai6 Grow quickly 5. \u9f8d\u99ac\u7cbe\u795e lung4 ma5 zing1 san4 Have the spirit of the horse and dragon 6. \u5b78\u696d\u9032\u6b65 hok6 yip6 zeon3 bou6 Progress in your education 7. \u5e74\u5e74\u6709\u9918 lin4 lin4 yau5 yue4 Excess in each year 8. \u51fa\u5165\u5e73\u5b89 cut1 yap6 ping4 on1 Leave and enter in safety 9. \u5fc3\u60f3\u4e8b\u6210 sam1 soeng2 si6 sing4 Accomplish that which is in your heart 10. \u751f\u610f\u8208\u9686 saang1 yi3 hing1 lung4 Have a prosperous business 11. \u842c\u4e8b\u5982\u610f maan6 si6 yu4 yi3 A thousand things according to your will 12. \u5929\u5929\u5411\u4e0a tin1 tin1 hoeng3 soeng6 Upwards and onwards every day 13. \u7b11\u53e3\u5e38\u958b siu3 hau2 soeng4 hoi1 Laugh with an open mouth frequently 14. \u5927\u5409\u5927\u5229 daai6 gat1 daai6 lei6 Much luck and much prosperity 15. \u4e94\u798f\u81e8\u9580 mm5 fuk1 lam4 mun4 Five blessings for your household 16. \u62db\u8ca1\u9032\u5bf6 ziu1 coi4 zeon3 bou2 Seek wealth welcome in the precious 17. \u76e4\u6eff\u7835\u6eff pun4 mun5 but3 mun5 Basins full of wealth The English sentences include List 60 from the Harvard Sentences and some holiday-themed additions to better match the Cantonese sentences. Thirteen of the sentences are imperatives. English sentence 1. Stop whistling and watch the boys march. 2. Jerk the cord, and out tumbles the gold. 3. Slide the tray across the glass top. 4. The cloud moved in a stately way and was gone. 5. Light maple makes for a swell room. 6. Set the piece here and say nothing. 7. Dull stories make her laugh. 8. A stiff cord will do to fasten your shoe. 9. Get the trust fund to the bank early. 10. Choose between the high road and the low. 11. Wish on every candle for your birthday. 12. Deck the halls with boughs of holly. 13. Ring in the new year with a kiss. 14. Have a spooky Halloween. 15. Enjoy the vacation with your loved ones. 16. Be filled with joy and peace during this time. 17. Relax on your holiday break.","title":"Task 1: Sentences"},{"location":"procedures/#task-2-storyboard","text":"Participants narrated the same cartoon in both languages, usually in just a few minutes. The cartoon\u2014 Thank You Notes \u2014was originally developed by Patrick Littell for linguistics field research and elicited vocabulary related to family members and simple gift-giving. While participants only viewed one panel at a time, here's what the cartoon looked like as a whole:","title":"Task 2: Storyboard"},{"location":"procedures/#task-3-interview","text":"The conversational interview accounted for the bulk of the session, and typically lasted around 25 minutes each. The interviews covered a variety of everyday topics such as culture, food, school, hobbies, and family. The sequence of topics with potential follow-up prompts and questions is available in the following documents. Note that the interviews were dynamic, in that the interviewer went along with what the participant wanted to discuss! As such, the content of interviews varies substantially. English interview questions PDF Cantonese interview questions PDF","title":"Task 3: Interview"},{"location":"transcription/","text":"How the files were transcribed This page is an extension of the description published in Johnson, Babel, Fong, & Yiu (2020) , and some of the text from the paper is reproduced verbatim. Overview Broadly, the transcription pipeline followed these steps: Files segmented into short chunks, with breaks placed during silences/breaths Initial transcripts produced with Google Cloud Speech-to-Text Hand-correction of orthographic transcripts by bilingual research assistants Force-aligned transcripts produced for segmental content The tools used in the process were: Praat (version 6+) Python libraries: parselmouth pycantonese jieba pydub ...and others Google Cloud Speech-to-Text Synchronous speech recognition (v1) ELAN (version 5.4+) Transcription guidelines were loosely adapted from the HLVC project Montreal Forced Aligner 1.0.1 Speech recognition Google Cloud Speech-to-Text has inexpensive options for both Canadian English ( en-CA ) and Hong Kong Cantonese ( yue-Hant-HK )\u2014it was used to produce an initial transcript, with the aim of expediting the orthographic transcription process. Anecdotally, it worked better for English than Cantonese. Of the available options, synchronous speech recognition with short audio files was desirable from an ethics perspective, as it allowed for the files remain in local storage rather than cloud storage. The files were sent to the cloud for processing, but were not logged by Google. To use this option, the audio files were first segmented into short chunks. This was done in Praat, by extracting the participant channel ( Convert - Extract one channel... ), marking silences ( Annotate - To TextGrid (silences) ), and manually adding and correcting such that individual chunks were under 15 seconds in length. This was done to facilitate subsequent manual correction. No attention was paid to constituents at this point, unless they coincided with a silence, pause, or breath. Using the timestamps from the Praat textgrid (Praat's annotation file type), short audio files were then extracted and downsampled to 16,000 Hz with pydub , and then processed with the Cloud Speech-to-Text Python client. The function used closely resembled that in the Cloud Speech-to-Text documentation for \"Performing synchronous speech recognition on a local file\" , copied below for ease of reference. Of the synchronous speech recognition output, both transcription and confidence were retained, and imported into ELAN for manual checking. def transcribe_file(speech_file): \"\"\"Transcribe the given audio file.\"\"\" from google.cloud import speech import io client = speech.SpeechClient() with io.open(speech_file, \"rb\") as audio_file: content = audio_file.read() audio = speech.RecognitionAudio(content=content) config = speech.RecognitionConfig( encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16, sample_rate_hertz=16000, language_code=\"en-US\", ) response = client.recognize(config=config, audio=audio) # Each result is for a consecutive portion of the audio. Iterate through # them to get the transcripts for the entire audio file. for result in response.results: # The first alternative is the most likely one for this portion. print(u\"Transcript: {}\".format(result.alternatives[0].transcript)) Orthographic hand correction Hand correction was done for participant speech in each of the interview files using ELAN. Note that while audible, the interviewer's speech was never transcribed. Further, instances that were considered to directly identify participants were silenced from the audio, and marked with \"xxx\" in the transcription. Conventions Some conventions apply to both lanugages: Transcriptions reflect exactly what was said, as it was said The placeholder \"xxx\" denotes unintelligible (and silenced) speech Fragments are transcribed using \"&\" followed by the fragment produced (e.g., \"&s\") The \"?\" symbol may mark questions; other punctuation is not used Cantonese-specific conventions were: Where possible, transcription comprises traditional characters Words without a standard traditional character are transcribed with Jyutping (e.g., jyut6ping3 ) Fully-lexicalized syllable fusion is transcribed with the typical smaller number of characters (e.g., \u54a9 me1 is a fully fused version of \u4e5c\u5622 mat1 ye5 , and intermediate version \u54a9\u5622 me1 ye5 \u2014all translate to \"what\") Non-lexicalized (or ambiguous) cases of syllable fusion are transcribed with the full number of characters fused (e.g., \u671d\u982d\u65e9, \"morning,\" is fully pronounced as ziu1 tau4 zou2 , but can be fused to\u3010\u671d\u982d\u3011\u65e9 ziau14zou2 ; brackets indicate the fused syllables) Filled pauses are transcribed with the character \u35a1 ( e6 ), or using Jyutping if different (e.g., m6 ) Words produced in Mandarin Chinese are transcribed in Mandarin (simplified) Chinese characters with \"@m\" appended to each A similar convention applied to other languages, such as \"@j\" for Japanese, and \"@ml\" for Malay Code-switches to English were not tagged with the @ symbol, merely written in English Numbers are written out in characters or jyutping, not using the 0-9 digits English-specific conventions were: Standard spelling was used (likely some variation between US/UK/Canadian spellings) Proper nouns are capitalized (and may be hyphenated if composed of multiple words, as with \"British-Columbia\") Filled pauses are transcribed with \"um\", \"er\", \"uh\", and other similar non -elongated forms Numbers are written out in word form (e.g., \"one hundred\") Cantonese word segmentation Following orthographic hand-correction, Cantonese text in both the Cantonese and English files was segmented using a minimally adapted version of the Cantonese Word Segmentation wordlist.txt and jieba Python package. Forced alignment Force-aligned transcripts were produced with the Montreal Forced Aligner 1.0.1, using the hand-corrected orthographic transcripts. The English files were aligned with the pretrained English model provided with the Montreal Forced Aligner. The Cantonese files were aligned with the train_and_align function, as a pretrained model was not available for Cantonese at the time of the corpus preparation and release. For English, an adapted version of the pronunciation dictionary provided with the Montreal Forced Aligner was used, which (while not a perfect choice) broadly reflects North American English varieties. For Cantonese, a pronunciation dictionary was generated by mapping the segmented characters to their Jyutping romanization with the pycantonese Python package, and supplementing it with manual entries (mostly for instances of syllable fusion). In this dictionary, tone numbers are always appended to the syllable nucelus. While the force aligned transcripts were inspected to ensure that the ouput looked approximately correct, this was a very coarse inspection, and involved no manual correction of the word or phone tiers. Note the English was not aligned in the Cantonese files, and Cantonese was not aligned in the English files. The acoustic models, pronunciation dictionaries, and out-of-vocabulary files for both languages are included with the SpiCE corpus download. The end product This transcription process led to the following output. For each audio recording, there is an accompanying Praat .TextGrid transcript with the same base filename. The transcript includes four tiers, and is pictured in the Praat screenshot below: task : Marks the portion of the interview as Sentences, Storyboard, or Interview utterance : The utterance that served as input to forced alignment. word : English or Cantonese word phone : The segment of English or Cantonese as identifed by forced alignment","title":"Transcription procedures"},{"location":"transcription/#how-the-files-were-transcribed","text":"This page is an extension of the description published in Johnson, Babel, Fong, & Yiu (2020) , and some of the text from the paper is reproduced verbatim.","title":"How the files were transcribed"},{"location":"transcription/#overview","text":"Broadly, the transcription pipeline followed these steps: Files segmented into short chunks, with breaks placed during silences/breaths Initial transcripts produced with Google Cloud Speech-to-Text Hand-correction of orthographic transcripts by bilingual research assistants Force-aligned transcripts produced for segmental content The tools used in the process were: Praat (version 6+) Python libraries: parselmouth pycantonese jieba pydub ...and others Google Cloud Speech-to-Text Synchronous speech recognition (v1) ELAN (version 5.4+) Transcription guidelines were loosely adapted from the HLVC project Montreal Forced Aligner 1.0.1","title":"Overview"},{"location":"transcription/#speech-recognition","text":"Google Cloud Speech-to-Text has inexpensive options for both Canadian English ( en-CA ) and Hong Kong Cantonese ( yue-Hant-HK )\u2014it was used to produce an initial transcript, with the aim of expediting the orthographic transcription process. Anecdotally, it worked better for English than Cantonese. Of the available options, synchronous speech recognition with short audio files was desirable from an ethics perspective, as it allowed for the files remain in local storage rather than cloud storage. The files were sent to the cloud for processing, but were not logged by Google. To use this option, the audio files were first segmented into short chunks. This was done in Praat, by extracting the participant channel ( Convert - Extract one channel... ), marking silences ( Annotate - To TextGrid (silences) ), and manually adding and correcting such that individual chunks were under 15 seconds in length. This was done to facilitate subsequent manual correction. No attention was paid to constituents at this point, unless they coincided with a silence, pause, or breath. Using the timestamps from the Praat textgrid (Praat's annotation file type), short audio files were then extracted and downsampled to 16,000 Hz with pydub , and then processed with the Cloud Speech-to-Text Python client. The function used closely resembled that in the Cloud Speech-to-Text documentation for \"Performing synchronous speech recognition on a local file\" , copied below for ease of reference. Of the synchronous speech recognition output, both transcription and confidence were retained, and imported into ELAN for manual checking. def transcribe_file(speech_file): \"\"\"Transcribe the given audio file.\"\"\" from google.cloud import speech import io client = speech.SpeechClient() with io.open(speech_file, \"rb\") as audio_file: content = audio_file.read() audio = speech.RecognitionAudio(content=content) config = speech.RecognitionConfig( encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16, sample_rate_hertz=16000, language_code=\"en-US\", ) response = client.recognize(config=config, audio=audio) # Each result is for a consecutive portion of the audio. Iterate through # them to get the transcripts for the entire audio file. for result in response.results: # The first alternative is the most likely one for this portion. print(u\"Transcript: {}\".format(result.alternatives[0].transcript))","title":"Speech recognition"},{"location":"transcription/#orthographic-hand-correction","text":"Hand correction was done for participant speech in each of the interview files using ELAN. Note that while audible, the interviewer's speech was never transcribed. Further, instances that were considered to directly identify participants were silenced from the audio, and marked with \"xxx\" in the transcription.","title":"Orthographic hand correction"},{"location":"transcription/#conventions","text":"Some conventions apply to both lanugages: Transcriptions reflect exactly what was said, as it was said The placeholder \"xxx\" denotes unintelligible (and silenced) speech Fragments are transcribed using \"&\" followed by the fragment produced (e.g., \"&s\") The \"?\" symbol may mark questions; other punctuation is not used Cantonese-specific conventions were: Where possible, transcription comprises traditional characters Words without a standard traditional character are transcribed with Jyutping (e.g., jyut6ping3 ) Fully-lexicalized syllable fusion is transcribed with the typical smaller number of characters (e.g., \u54a9 me1 is a fully fused version of \u4e5c\u5622 mat1 ye5 , and intermediate version \u54a9\u5622 me1 ye5 \u2014all translate to \"what\") Non-lexicalized (or ambiguous) cases of syllable fusion are transcribed with the full number of characters fused (e.g., \u671d\u982d\u65e9, \"morning,\" is fully pronounced as ziu1 tau4 zou2 , but can be fused to\u3010\u671d\u982d\u3011\u65e9 ziau14zou2 ; brackets indicate the fused syllables) Filled pauses are transcribed with the character \u35a1 ( e6 ), or using Jyutping if different (e.g., m6 ) Words produced in Mandarin Chinese are transcribed in Mandarin (simplified) Chinese characters with \"@m\" appended to each A similar convention applied to other languages, such as \"@j\" for Japanese, and \"@ml\" for Malay Code-switches to English were not tagged with the @ symbol, merely written in English Numbers are written out in characters or jyutping, not using the 0-9 digits English-specific conventions were: Standard spelling was used (likely some variation between US/UK/Canadian spellings) Proper nouns are capitalized (and may be hyphenated if composed of multiple words, as with \"British-Columbia\") Filled pauses are transcribed with \"um\", \"er\", \"uh\", and other similar non -elongated forms Numbers are written out in word form (e.g., \"one hundred\")","title":"Conventions"},{"location":"transcription/#cantonese-word-segmentation","text":"Following orthographic hand-correction, Cantonese text in both the Cantonese and English files was segmented using a minimally adapted version of the Cantonese Word Segmentation wordlist.txt and jieba Python package.","title":"Cantonese word segmentation"},{"location":"transcription/#forced-alignment","text":"Force-aligned transcripts were produced with the Montreal Forced Aligner 1.0.1, using the hand-corrected orthographic transcripts. The English files were aligned with the pretrained English model provided with the Montreal Forced Aligner. The Cantonese files were aligned with the train_and_align function, as a pretrained model was not available for Cantonese at the time of the corpus preparation and release. For English, an adapted version of the pronunciation dictionary provided with the Montreal Forced Aligner was used, which (while not a perfect choice) broadly reflects North American English varieties. For Cantonese, a pronunciation dictionary was generated by mapping the segmented characters to their Jyutping romanization with the pycantonese Python package, and supplementing it with manual entries (mostly for instances of syllable fusion). In this dictionary, tone numbers are always appended to the syllable nucelus. While the force aligned transcripts were inspected to ensure that the ouput looked approximately correct, this was a very coarse inspection, and involved no manual correction of the word or phone tiers. Note the English was not aligned in the Cantonese files, and Cantonese was not aligned in the English files. The acoustic models, pronunciation dictionaries, and out-of-vocabulary files for both languages are included with the SpiCE corpus download.","title":"Forced alignment"},{"location":"transcription/#the-end-product","text":"This transcription process led to the following output. For each audio recording, there is an accompanying Praat .TextGrid transcript with the same base filename. The transcript includes four tiers, and is pictured in the Praat screenshot below: task : Marks the portion of the interview as Sentences, Storyboard, or Interview utterance : The utterance that served as input to forced alignment. word : English or Cantonese word phone : The segment of English or Cantonese as identifed by forced alignment","title":"The end product"}]}